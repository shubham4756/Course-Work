{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3017c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, os, subprocess, code, glob, re, traceback, sys, inspect\n",
    "# from time import clock, sleep\n",
    "from tika import parser\n",
    "import re\n",
    "\n",
    "# filename = input('Enter the path to the resume: ')\n",
    "\n",
    "filename = 'resume3.pdf'\n",
    "\n",
    "print(filename)\n",
    "\n",
    "parsed_pdf = parser.from_file(filename)\n",
    "\n",
    "data = parsed_pdf['content']\n",
    "\n",
    "res = re.sub('\\s\\s+', ' ', data) # remove extra space\n",
    "\n",
    "data1 = res\n",
    "try:\n",
    "    data1 = str(res)\n",
    "except:\n",
    "    print('Error')\n",
    "    \n",
    "print('**********************************\\n')\n",
    "print('Raw Data')\n",
    "print(data1)\n",
    "print('**********************************\\n\\n\\n')\n",
    "\n",
    "file1 = open(\"rawdata.txt\",\"w\",encoding=\"utf-8\")\n",
    "file1.write(data1)\n",
    "file1.close()\n",
    "\n",
    "data = ''\n",
    "try:\n",
    "    data = str(data.strip())\n",
    "except:\n",
    "    data = data.strip()\n",
    "\n",
    "p = \"\"\n",
    "f = False\n",
    "\n",
    "for ch in data:\n",
    "    if ch == '\\n':\n",
    "        f = True\n",
    "    else:\n",
    "        if f == True:\n",
    "            f = False\n",
    "            p = p + '\\n'\n",
    "        p = p + ch\n",
    "\n",
    "data = ''\n",
    "try:\n",
    "    data = str(p)\n",
    "except:\n",
    "    data = p\n",
    "\n",
    "p = \"\"\n",
    "f = False\n",
    "\n",
    "for ch in data:\n",
    "    if ch == ' ':\n",
    "        f = True\n",
    "    else:\n",
    "        if f == True:\n",
    "            f = False\n",
    "            p = p + ' '\n",
    "        p = p + ch\n",
    "\n",
    "data = ''\n",
    "try:\n",
    "    data = str(p)\n",
    "except:\n",
    "    data = p\n",
    "\n",
    "        \n",
    "file1 = open(\"data.txt\",\"w\",encoding=\"utf-8\")\n",
    "file1.write(data)\n",
    "file1.close()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cb39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def convertPDFToText(path):\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = open(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    string = retstr.getvalue()\n",
    "    retstr.close()\n",
    "    return string\n",
    "\n",
    "def preprocess(document):\n",
    "    '''\n",
    "    Information Extraction: Preprocess a document with the necessary POS tagging.\n",
    "    Returns three lists, one with tokens, one with POS tagged lines, one with POS tagged sentences.\n",
    "    Modules required: nltk\n",
    "    '''\n",
    "    try:\n",
    "        # Try to get rid of special characters\n",
    "        try:\n",
    "            document = document.decode('ascii', 'ignore')\n",
    "        except:\n",
    "            document = document.encode('ascii', 'ignore')\n",
    "        # Newlines are one element of structure in the data\n",
    "        # Helps limit the context and breaks up the data as is intended in resumes - i.e., into points\n",
    "        lines = [el.strip() for el in document.split(\"\\n\") if len(el) > 0]  # Splitting on the basis of newlines \n",
    "        # lines = [nltk.word_tokenize(el) for el in lines]    # Tokenize the individual lines\n",
    "        \n",
    "        #POS tagging\n",
    "        # lines = [nltk.pos_tag(el) for el in lines]  # Tag them\n",
    "        \n",
    "        # Below approach is slightly different because it splits sentences not just on the basis of newlines, but also full stops \n",
    "        # - (barring abbreviations etc.)\n",
    "        # But it fails miserably at predicting names, so currently using it only for tokenization of the whole document\n",
    "        sentences = nltk.sent_tokenize(document)    # Split/Tokenize into sentences (List of strings)\n",
    "        tokens = [nltk.word_tokenize(sent) for sent in sentences]    # Split/Tokenize sentences into words (List of lists of strings)\n",
    "        \n",
    "        \n",
    "        #POS tagging\n",
    "        # sentences = [nltk.pos_tag(sent) for sent in sentences]    # Tag the tokens - list of lists of tuples - each tuple is (<word>, <tag>)\n",
    "        \n",
    "        \n",
    "        # Next 4 lines convert tokens from a list of list of strings to a list of strings; basically stitches them together\n",
    "        dummy = []\n",
    "        for el in tokens:\n",
    "            dummy += el\n",
    "        tokens = dummy\n",
    "        # tokens - words extracted from the doc, lines - split only based on newlines (may have more than one sentence)\n",
    "        # sentences - split on the basis of rules of grammar\n",
    "        return tokens, lines, sentences\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "filename = 'resume3.pdf'\n",
    "data = convertPDFToText(filename)\n",
    "file1 = open(\"data_miner.txt\",\"w\",encoding=\"utf-8\")\n",
    "file1.write(data)\n",
    "file1.close()\n",
    "\n",
    "#open text file in read mode\n",
    "text_file = open(\"data_miner.txt\", \"rb\")\n",
    "\n",
    "#read whole file to a string\n",
    "data1 = text_file.read()\n",
    "\n",
    "\n",
    "#close file\n",
    "text_file.close()\n",
    "\n",
    "        \n",
    "# tokenize\n",
    "try:\n",
    "    [tokens, lines, sentences] = preprocess(data1)\n",
    "except Exception as e:\n",
    "    e\n",
    "\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440032bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3021039",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5640be5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanResume(resumeText):\n",
    "    resumeText = re.sub('http\\S+\\s*', ' ', resumeText)  # remove URLs\n",
    "    resumeText = re.sub('RT|cc', ' ', resumeText)  # remove RT and cc\n",
    "    resumeText = re.sub(r'[^\\x00-\\x7f]',r' ', resumeText) \n",
    "    resumeText = re.sub(' +', ' ', resumeText)\n",
    "    return resumeText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmail(inputString): \n",
    "        '''\n",
    "        Given an input string, returns possible matches for emails. Uses regular expression based matching.\n",
    "        Needs an input string, a dictionary where values are being stored, and an optional parameter for debugging.\n",
    "        Modules required: clock from time, code.\n",
    "        '''\n",
    "\n",
    "        email = None\n",
    "        try:\n",
    "            pattern = re.compile(r'\\S*@\\S*')\n",
    "            matches = pattern.findall(inputString) # Gets all email addresses as a list\n",
    "            email = matches\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b16cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPhone(inputString):\n",
    "        '''\n",
    "        Given an input string, returns possible matches for phone numbers. Uses regular expression based matching.\n",
    "        Needs an input string, a dictionary where values are being stored, and an optional parameter for debugging.\n",
    "        Modules required: clock from time, code.\n",
    "        '''\n",
    "\n",
    "        number = None\n",
    "        try:\n",
    "            pattern = re.compile(r'([+(]?\\d+[)\\-]?[ \\t\\r\\f\\v]*[(]?\\d{2,}[()\\-]?[ \\t\\r\\f\\v]*\\d{2,}[()\\-]?[ \\t\\r\\f\\v]*\\d*[ \\t\\r\\f\\v]*\\d*[ \\t\\r\\f\\v]*)')\n",
    "                # Understanding the above regex\n",
    "                # +91 or (91) -> [+(]? \\d+ -?\n",
    "                # Metacharacters have to be escaped with \\ outside of character classes; inside only hyphen has to be escaped\n",
    "                # hyphen has to be escaped inside the character class if you're not incidication a range\n",
    "                # General number formats are 123 456 7890 or 12345 67890 or 1234567890 or 123-456-7890, hence 3 or more digits\n",
    "                # Amendment to above - some also have (0000) 00 00 00 kind of format\n",
    "                # \\s* is any whitespace character - careful, use [ \\t\\r\\f\\v]* instead since newlines are trouble\n",
    "            match = pattern.findall(inputString)\n",
    "            # match = [re.sub(r'\\s', '', el) for el in match]\n",
    "                # Get rid of random whitespaces - helps with getting rid of 6 digits or fewer (e.g. pin codes) strings\n",
    "            # substitute the characters we don't want just for the purpose of checking\n",
    "            match = [re.sub(r'[,.]', '', el) for el in match if len(re.sub(r'[()\\-.,\\s+]', '', el))>6]\n",
    "                # Taking care of years, eg. 2001-2004 etc.\n",
    "            match = [re.sub(r'\\D$', '', el).strip() for el in match]\n",
    "                # $ matches end of string. This takes care of random trailing non-digit characters. \\D is non-digit characters\n",
    "            match = [el for el in match if len(re.sub(r'\\D','',el)) <= 15]\n",
    "                # Remove number strings that are greater than 15 digits\n",
    "            try:\n",
    "                for el in list(match):\n",
    "                    # Create a copy of the list since you're iterating over it\n",
    "                    if len(el.split('-')) > 3: continue # Year format YYYY-MM-DD\n",
    "                    for x in el.split(\"-\"):\n",
    "                        try:\n",
    "                            # Error catching is necessary because of possibility of stray non-number characters\n",
    "                            # if int(re.sub(r'\\D', '', x.strip())) in range(1900, 2100):\n",
    "                            if x.strip()[-4:].isdigit():\n",
    "                                if int(x.strip()[-4:]) in range(1900, 2100):\n",
    "                                    # Don't combine the two if statements to avoid a type conversion error\n",
    "                                    match.remove(el)\n",
    "                        except:\n",
    "                            pass\n",
    "            except:\n",
    "                pass\n",
    "            number = match\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf95c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getName(data):\n",
    "    #Define your grammar using regular expressions\n",
    "    grammar = r\"\"\"Chunk: {<NNP><NNP>+}\"\"\"\n",
    "    chunkParser = nltk.RegexpParser(grammar)\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(data))\n",
    "    chunked = chunkParser.parse(tagged)\n",
    "#     print(chunked.draw())\n",
    "    name = '';\n",
    "    for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Chunk'):\n",
    "        name = str(subtree[0][0]) + ' ' + str(subtree[1][0])\n",
    "        break\n",
    "        \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e7631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bytes datatype to string\n",
    "data = data1.decode('ISO-8859-1')\n",
    "\n",
    "print(getEmail(data))\n",
    "print(getPhone(data))\n",
    "print(getName(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990cdcc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text_file = open(\"data_miner.txt\", \"rb\")\n",
    "\n",
    "data_tika1 = text_file.read()\n",
    "\n",
    "data_tika = data_tika1.decode('ISO-8859-1')\n",
    "\n",
    "\n",
    "data_tika = cleanResume(data_tika)\n",
    "\n",
    "# print(data_tika)\n",
    "\n",
    "def getExperience(sentence):\n",
    "    data = \"\".join([words.lower() for words in sentence])\n",
    "#     print(data)\n",
    "    if re.search('experience', data):\n",
    "        sen_tokenised = nltk.word_tokenize(data)\n",
    "        tagged = nltk.pos_tag(sen_tokenised)\n",
    "        entities = nltk.chunk.ne_chunk(tagged)\n",
    "        experience = False\n",
    "        for subtree in entities.subtrees():\n",
    "            for leaf in subtree.leaves():\n",
    "                if leaf[1] == 'CD':\n",
    "                    experience = leaf[0]\n",
    "        return experience\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "\n",
    "linesOfResume = [el.strip() for el in data_tika.split(\"\\n\") if len(el) > 0]\n",
    "\n",
    "for line in linesOfResume:\n",
    "    res = getExperience(line)\n",
    "    if (res != False):\n",
    "        print(line + ' -----------> ' + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572f31b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
